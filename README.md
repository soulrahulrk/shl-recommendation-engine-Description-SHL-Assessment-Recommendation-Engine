# SHL Assessment Recommendation Engine

An intelligent recommendation system for SHL assessments using semantic search and LLM re-ranking.

## âœ… Requirements Checklist

| Requirement | Status | Details |
|------------|--------|---------|
| Crawl SHL Catalog | âœ… Done | 377 Individual Test Solutions crawled |
| Build Recommendation Engine | âœ… Done | Semantic search + LLM re-ranking |
| Natural Language Query Support | âœ… Done | Text/JD input supported |
| Return 1-10 Assessments | âœ… Done | Returns top 10 relevant assessments |
| Assessment Name + URL | âœ… Done | Full metadata included |
| API Endpoint (JSON) | âœ… Done | FastAPI at `/recommend` |
| Web Frontend | âœ… Done | Streamlit app |
| GitHub Repository | âœ… Done | Ready for submission |
| Submission CSV | âœ… Done | `submission.csv` generated |
| Mean Recall@10 Evaluation | âœ… Done | 22.11% with LLM reranking |
| LLM Integration | âœ… Done | Groq Llama-3.3-70B (Free) |
| Balanced Recommendations | âœ… Done | Hard + Soft skills mix |

## ğŸŒŸ Features

- **Semantic Search**: sentence-transformers embeddings (all-MiniLM-L6-v2)
- **LLM Re-ranking**: Groq Llama-3.3-70B for intelligent re-ordering
- **377 Assessments**: Complete SHL Individual Test Solutions catalog
- **REST API**: FastAPI backend with OpenAPI docs
- **Web Interface**: Streamlit frontend for testing

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/yourusername/shl-recommendation-engine.git
cd shl-recommendation-engine

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Key (Optional)

For LLM re-ranking, get a **free** HuggingFace API key:

1. Go to https://huggingface.co and create a free account
2. Go to **Settings** â†’ **Access Tokens** (https://huggingface.co/settings/tokens)
3. Click **"New token"** â†’ Name it â†’ Select **"Read"** â†’ Create
4. Copy the token (starts with `hf_...`)

```bash
# Create .env file
echo "HF_API_KEY=hf_your_token_here" > .env
```

### 3. Run the Application

**Option A: Streamlit Frontend**
```bash
streamlit run app.py
```
Opens at http://localhost:8501

**Option B: FastAPI Backend**
```bash
uvicorn api:app --reload
```
- API: http://localhost:8000
- Docs: http://localhost:8000/docs

## ğŸ“Š API Usage

### POST /recommend

```python
import requests

response = requests.post("http://localhost:8000/recommend", json={
    "query": "Looking for Java developers with team collaboration skills",
    "top_k": 10,
    "use_llm": True
})

print(response.json())
```

### Response Format

```json
{
  "query": "Looking for Java developers...",
  "method": "semantic+llm_rerank",
  "recommendations": [
    {
      "rank": 1,
      "assessment_name": "Core Java (Entry Level) - New",
      "url": "https://www.shl.com/products/...",
      "test_types": ["Knowledge & Skills"],
      "reason": "Directly assesses Java programming skills"
    }
  ],
  "processing_time_ms": 250.5
}
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query     â”‚â”€â”€â”€â–¶â”‚  Semantic Search â”‚â”€â”€â”€â–¶â”‚  LLM Re-ranking â”‚
â”‚  (Job Desc/URL) â”‚    â”‚  (FAISS + MiniLM)â”‚    â”‚  (Gemini Flash) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Top-20 Candidatesâ”‚â”€â”€â”€â–¶â”‚  Top-10 Balancedâ”‚
                       â”‚  (by similarity)  â”‚    â”‚  (hard+soft mix)â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
shl-recommendation-engine/
â”œâ”€â”€ api.py                        # FastAPI backend (POST /recommend, GET /health)
â”œâ”€â”€ app.py                        # Streamlit frontend
â”œâ”€â”€ pipeline.py                   # End-to-end pipeline
â”œâ”€â”€ evaluate.py                   # Evaluation script (Mean Recall@10)
â”œâ”€â”€ generate_submission.py        # Generate submission CSV
â”œâ”€â”€ submission.csv                # Predictions for test set
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ README.md                     # Documentation
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ catalog_enriched.json     # 377 Individual Test Solutions
â”‚   â”œâ”€â”€ vector_store.faiss        # FAISS vector index
â”‚   â””â”€â”€ metadata.pkl              # Test metadata
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler.py                # Web crawler for SHL catalog
â”‚   â””â”€â”€ vector_store.py           # Vector store implementation
â””â”€â”€ llm/
    â”œâ”€â”€ prompt.txt                # LLM re-ranking prompt
    â””â”€â”€ rerank.py                 # Groq LLM re-ranking module
```

## ğŸ“ˆ Evaluation Results

Mean Recall@10 on the training dataset:

| Method | Mean Recall@10 |
|--------|----------------|
| Semantic Only | 20.56% |
| **Semantic + LLM** | **22.11%** |

Run evaluation:
```bash
python evaluate.py --dataset "Gen_AI Dataset.xlsx"
```

Generate submission:
```bash
python generate_submission.py --dataset "Gen_AI Dataset.xlsx" --output submission.csv
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GROQ_API_KEY` | Groq API key (FREE at console.groq.com) | For LLM re-ranking |

### Vector Store Settings

- Model: `all-MiniLM-L6-v2` (384 dimensions)
- Index: FAISS IndexFlatIP (cosine similarity)
- Candidate pool: 20 for re-ranking, configurable

## ğŸ“ Assessment Types

| Code | Type | Description |
|------|------|-------------|
| K | Knowledge & Skills | Technical/hard skills (programming, etc.) |
| P | Personality | Personality assessments (OPQ, etc.) |
| B | Behavioral | Behavioral competencies |
| A | Ability | Cognitive abilities |
| S | Simulation | Job simulations |

## ğŸ› ï¸ Development

### Rebuild Vector Index

```bash
python -c "from src.vector_store import SHLVectorStore; s = SHLVectorStore(); s.build_index(); s.save()"
```

### Run Tests

```bash
python -m pytest tests/
```

## ğŸ“œ License

MIT License

## ğŸ™ Acknowledgments

- [SHL](https://www.shl.com) for the comprehensive assessment catalog
- [Sentence Transformers](https://www.sbert.net/) for the embedding models
- [Groq](https://groq.com/) for providing free LLM API access
